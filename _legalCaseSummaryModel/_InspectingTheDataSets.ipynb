{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb64de0-e36b-483e-8ca7-859a834fbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd8246a-0dc0-4c05-a927-3c41bfe97f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print sample rows\n",
    "def print_sample(dataset, dataset_name, num_samples=3):\n",
    "    print(f\"--- Sample from {dataset_name} ---\")\n",
    "    for i in range(num_samples):\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        \n",
    "        # Print the first 250 characters of the text\n",
    "        text_sample = dataset[i]['text'][:250] if isinstance(dataset[i]['text'], str) else dataset[i]['text']\n",
    "        print(\"Text:\", text_sample, \"...\")\n",
    "        \n",
    "        # Check if 'labels' is a list or an int\n",
    "        labels_sample = dataset[i]['labels']\n",
    "        if isinstance(labels_sample, list):\n",
    "            # Slice only if it's a list\n",
    "            print(\"Labels:\", labels_sample[:250], \"...\")\n",
    "        else:\n",
    "            # Just print the integer or scalar value\n",
    "            print(\"Labels:\", labels_sample, \"...\")\n",
    "        \n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92de2db7-e08f-4a40-90d7-13d266ed6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for length checking the 'text' column of a dataset\n",
    "def check_text_lengths(dataset, name):\n",
    "    lengths = [len(text) for text in dataset['text']]  # Adjust key if needed\n",
    "    print(f\"{name} - Min length: {min(lengths)}, Max length: {max(lengths)}, Mean length: {sum(lengths) / len(lengths)}\")\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be76e48-b005-4bbf-a543-8f0ace828b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for length checking the 'labels' column of a dataset\n",
    "def check_labels_lengths(dataset, name):\n",
    "    lengths = []\n",
    "    for label in dataset['labels']:\n",
    "        if isinstance(label, (list, str)):  # If label is a list or string, we can compute its length\n",
    "            lengths.append(len(label))\n",
    "        else:\n",
    "            lengths.append(1)  # If it's an int or scalar, treat the length as 1\n",
    "    \n",
    "    # Print the min, max, and mean length of the labels\n",
    "    print(f\"{name} - Min length: {min(lengths)}, Max length: {max(lengths)}, Mean length: {sum(lengths) / len(lengths)}\")\n",
    "    \n",
    "    return lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e85f12-def9-4153-ab6e-8b37917a219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "def check_missing_data(dataset, name):\n",
    "    missing = [i for i, text in enumerate(dataset['text']) if not text]  # Adjust key if needed\n",
    "    print(f\"{name} - Missing entries: {len(missing)}\")\n",
    "    if missing:\n",
    "        print(f\"Indices with missing entries: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d30c7e-2e65-44d5-94ff-8208d2857908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing data\n",
    "\n",
    "# ds1: Legal case document summarization\n",
    "ds1_train = load_dataset(\"joelniklaus/legal_case_document_summarization\", split='train')\n",
    "ds1_train = ds1_train.remove_columns(['dataset_name'])\n",
    "ds1_train = ds1_train.rename_column('judgement', 'text')\n",
    "ds1_train = ds1_train.rename_column('summary', 'labels')\n",
    "\n",
    "ds1_test = load_dataset(\"joelniklaus/legal_case_document_summarization\", split='test')\n",
    "ds1_test = ds1_test.remove_columns(['dataset_name'])\n",
    "ds1_test = ds1_test.rename_column('judgement', 'text')\n",
    "ds1_test = ds1_test.rename_column('summary', 'labels')\n",
    "\n",
    "# ds2: Legal document summary\n",
    "ds2 = load_dataset(\"manasvikalyan/legal-documents-summary\")\n",
    "ds2 = ds2['data']\n",
    "ds2 = ds2.remove_columns(['summary_a2'])\n",
    "ds2 = ds2.rename_column('summary_a1', 'labels')\n",
    "ds2 = ds2.rename_column('judgement', 'text')\n",
    "\n",
    "# ds3: LexGLUE - Case_hold (might not be suitable for summarization)\n",
    "ds3_train = load_dataset(\"coastalcph/lex_glue\", \"case_hold\", split='train')\n",
    "ds3_train = ds3_train.rename_column('label', 'labels')\n",
    "ds3_test = load_dataset(\"coastalcph/lex_glue\", \"case_hold\", split='test')\n",
    "ds3_test = ds3_test.rename_column('label', 'labels')\n",
    "\n",
    "# ds4: LexGLUE - ecthr_a\n",
    "ds4_train = load_dataset(\"coastalcph/lex_glue\", \"ecthr_a\", split='train')\n",
    "ds4_test = load_dataset(\"coastalcph/lex_glue\", \"ecthr_a\", split='test')\n",
    "\n",
    "# ds5: LexGLUE - ecthr_b\n",
    "ds5_train = load_dataset(\"coastalcph/lex_glue\", \"ecthr_b\", split='train')\n",
    "ds5_test = load_dataset(\"coastalcph/lex_glue\", \"ecthr_b\", split='test')\n",
    "\n",
    "# ds6: LexGLUE - eurlex\n",
    "ds6_train = load_dataset(\"coastalcph/lex_glue\", \"eurlex\", split='train')\n",
    "ds6_test = load_dataset(\"coastalcph/lex_glue\", \"eurlex\", split='test')\n",
    "\n",
    "# ds7: LexGLUE - ledgar\n",
    "ds7_train = load_dataset(\"coastalcph/lex_glue\", \"ledgar\", split='train')\n",
    "ds7_train = ds7_train.rename_column('label', 'labels')\n",
    "ds7_test = load_dataset(\"coastalcph/lex_glue\", \"ledgar\", split='test')\n",
    "ds7_test = ds7_test.rename_column('label', 'labels')\n",
    "\n",
    "# ds8: LexGLUE - scotus\n",
    "ds8_train = load_dataset(\"coastalcph/lex_glue\", \"scotus\", split='train')\n",
    "ds8_train = ds8_train.rename_column('label', 'labels')\n",
    "ds8_test = load_dataset(\"coastalcph/lex_glue\", \"scotus\", split='test')\n",
    "ds8_test = ds8_test.rename_column('label', 'labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3942729-168d-4b27-a8e0-593da45334b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 7773\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 50\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'endings', 'labels'],\n",
      "    num_rows: 45000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 9000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 9000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 55000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 60000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Print the structures of the datasets\n",
    "print(ds1_train)\n",
    "print(ds2)\n",
    "print(ds3_train)\n",
    "print(ds4_train)\n",
    "print(ds5_train)\n",
    "print(ds6_train)\n",
    "print(ds7_train)\n",
    "print(ds8_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e996e78-397c-40b8-86d4-37ad9235b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample from ds1_train ---\n",